{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974d5cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (C) Copyright 1996- ECMWF.\n",
    "#\n",
    "# This software is licensed under the terms of the Apache Licence Version 2.0\n",
    "# which can be obtained at http://www.apache.org/licenses/LICENSE-2.0.\n",
    "# In applying this licence, ECMWF does not waive the privileges and immunities\n",
    "# granted to it by virtue of its status as an intergovernmental organisation\n",
    "# nor does it submit to any jurisdiction.\n",
    "\n",
    "\"\"\"Metrics module - Standard metric definitions\"\"\"\n",
    "\n",
    "from typing import Union\n",
    "\n",
    "import attrs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pylab import arange\n",
    "from scipy.ndimage import measurements\n",
    "\n",
    "@attrs.define(eq = False)\n",
    "class Metric:\n",
    "    key: str = attrs.field(default=\"unknown\", validator=attrs.validators.instance_of(str))\n",
    "    name: str = attrs.field(default=\"unknown\", validator=attrs.validators.instance_of(str))\n",
    "    variable: str = attrs.field(default=\"unknown\", validator=attrs.validators.instance_of(str))\n",
    "    threshold_value: float = attrs.field(default=\"unknown\", validator=attrs.validators.instance_of(float), converter = float)\n",
    "    threshold_sign: str = attrs.field(default=None, validator=attrs.validators.instance_of((str, type(None))))\n",
    "    \n",
    "    def calculate_instances_of_threshold_exceedance(self, dataset):\n",
    "        \n",
    "        \"\"\"\n",
    "        Converts np.ndarray of input data (observations or climate projections) into 1-0 np.ndarray of same dimensions based on\n",
    "        threshold value and sign. Assignes 1 if value is below/above specified threshold (exceedance over threshold - eot), 0 otherwise.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dataset: np.ndarray\n",
    "            Input data, either observations or climate projectionsdataset to be analysed, numeric entries expected\n",
    "        threshold_name: str\n",
    "            Name of threshold metric specified in the metrics dictionary\n",
    "        \"\"\"\n",
    "\n",
    "        instances_of_threshold_exceedance = np.copy(dataset)\n",
    "\n",
    "        if self.threshold_sign == \"higher\":\n",
    "\n",
    "            instances_of_threshold_exceedance = (instances_of_threshold_exceedance > self.threshold_value).astype(int)\n",
    "\n",
    "        elif self.threshold_sign == \"lower\":\n",
    "\n",
    "            instances_of_threshold_exceedance = (instances_of_threshold_exceedance < self.threshold_value).astype(int)\n",
    "\n",
    "        else:\n",
    "            raise ValueError('Invalid threshold sign. Modify threshold_sign to either higher or lower in class instantiation')\n",
    "\n",
    "        return instances_of_threshold_exceedance\n",
    "    \n",
    "    \n",
    "    def filter_threshold_exceedances(self, dataset):\n",
    "        \n",
    "        eot_matrix = np.copy(dataset)\n",
    "        \n",
    "        if self.threshold_sign == \"higher\":\n",
    "            eot_matrix[eot_matrix < self.threshold_value] = 0\n",
    "            \n",
    "        elif self.threshold_sign == \"lower\":  \n",
    "            eot_matrix[eot_matrix > self.threshold_value] = 0\n",
    "            \n",
    "        else:\n",
    "            raise ValueError('Invalid threshold sign. Modify threshold_sign to either higher or lower in class instantiation')\n",
    "\n",
    "        return eot_matrix\n",
    "            \n",
    "        \n",
    "    def calculate_exceedance_probability(self, dataset):\n",
    "        \n",
    "        \"\"\"\n",
    "        Calculates the probability of exceeding a specified threshold at each location,\n",
    "        building on the function calculate_matrix.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        dataset: np.ndarray\n",
    "            Input data, either observations or climate projectionsdataset to be analysed, numeric entries expected\n",
    "        threshold_name: str\n",
    "            Name of threshold metric specified in the metrics dictionary\n",
    "        \"\"\"\n",
    "        \n",
    "        threshold_data = self.calculate_instances_of_threshold_exceedance(dataset)\n",
    "\n",
    "        threshold_probability = np.einsum('ijk -> jk', threshold_data)/threshold_data.shape[0]\n",
    "\n",
    "        return threshold_probability\n",
    "        \n",
    "        \n",
    "    def calculate_exceedances_per_time_period(self, dataset, time_period):\n",
    "        print('to-do')\n",
    "        \n",
    "        \n",
    "        \n",
    "    def calculate_spell_length(self, minimum_length, **climate_data):\n",
    "        \n",
    "        spell_length_array = np.empty((0, 3))\n",
    "    \n",
    "        for k in climate_data.keys():\n",
    "    \n",
    "            threshold_data = self.calculate_instances_of_threshold_exceedance(climate_data[k])\n",
    "            spell_length = np.array([])\n",
    "    \n",
    "            for i in range(threshold_data.shape[1]):\n",
    "                for j in range(threshold_data.shape[2]):\n",
    "                    N = 0\n",
    "                    for t in range(threshold_data.shape[0]):\n",
    "                        if threshold_data[t, i, j] == 1:\n",
    "                            N = N + 1\n",
    "                        elif (threshold_data[t, i, j] == 0) and (N != 0):\n",
    "                            spell_length = np.append(spell_length, N)\n",
    "                            N = 0\n",
    "    \n",
    "            spell_length = spell_length[spell_length > minimum_length]\n",
    "    \n",
    "            spell_length_array = np.append(\n",
    "                spell_length_array,\n",
    "                np.transpose(\n",
    "                    np.array(\n",
    "                        [\n",
    "                            [k] * len(spell_length),\n",
    "                            [self.name] * len(spell_length),\n",
    "                            np.transpose(spell_length),\n",
    "                        ]\n",
    "                    )\n",
    "                ),\n",
    "                axis=0,\n",
    "            )\n",
    "    \n",
    "        plot_data = pd.DataFrame(spell_length_array, columns=[\"Correction Method\", \"Metric\", \"Spell length (days)\"])\n",
    "        plot_data[\"Spell length (days)\"] = pd.to_numeric(plot_data[\"Spell length (days)\"])\n",
    "    \n",
    "        return plot_data\n",
    "    \n",
    "    \n",
    "        \n",
    "    def calculate_spatial_clusters(self, **climate_data):\n",
    "        \n",
    "        clusters_array = np.empty((0, 3))\n",
    "\n",
    "        for k in climate_data.keys():\n",
    "\n",
    "            spatial_count = np.array([])\n",
    "\n",
    "            number_gridpoints = climate_data[k].shape[1] * climate_data[k].shape[2]\n",
    "\n",
    "            threshold_data = self.calculate_instances_of_threshold_exceedance(dataset=climate_data[k])\n",
    "\n",
    "            for i in range(threshold_data.shape[0]):\n",
    "\n",
    "                count = np.sum(threshold_data[i, :, :]) / number_gridpoints\n",
    "                spatial_count = np.append(spatial_count, count)\n",
    "\n",
    "            spatial_count = spatial_count[spatial_count != 0]\n",
    "\n",
    "            clusters_array = np.append(\n",
    "                clusters_array,\n",
    "                np.transpose(\n",
    "                    np.array(\n",
    "                        [\n",
    "                            [k] * len(spatial_count),\n",
    "                            [self.name] * len(spatial_count),\n",
    "                            np.transpose(spatial_count),\n",
    "                        ]\n",
    "                    )\n",
    "                ),\n",
    "                axis=0,\n",
    "            )\n",
    "\n",
    "        spatial_clusters = pd.DataFrame(\n",
    "            clusters_array, columns=[\"Correction Method\", \"Metric\", \"Spatial extent (% of area)\"]\n",
    "        )\n",
    "        spatial_clusters[\"Spatial extent (% of area)\"] = pd.to_numeric(spatial_clusters[\"Spatial extent (% of area)\"])\n",
    "\n",
    "        return spatial_clusters\n",
    "        \n",
    "        \n",
    "        \n",
    "    def calculate_spatiotemporal_clusters(self, **climate_data):\n",
    "        \n",
    "        clusters_array = np.empty((0, 3))\n",
    "\n",
    "        for k in climate_data.keys():\n",
    "\n",
    "            threshold_data = self.calculate_instances_of_threshold_exceedance(dataset=climate_data[k])\n",
    "            threshold_data_lw, threshold_data_num = measurements.label(threshold_data)\n",
    "            area = measurements.sum(threshold_data, threshold_data_lw, index=arange(threshold_data_lw.max() + 1))\n",
    "\n",
    "            clusters_array = np.append(\n",
    "                clusters_array,\n",
    "                np.transpose(\n",
    "                    np.array(\n",
    "                        [[k] * len(area), [self.name] * len(area), np.transpose(area)]\n",
    "                    )\n",
    "                ),\n",
    "                axis=0,\n",
    "            )\n",
    "\n",
    "        spatiotemporal_clusters = pd.DataFrame(\n",
    "            clusters_array, columns=[\"Correction Method\", \"Metric\", \"Spatiotemporal cluster size\"]\n",
    "        )\n",
    "        spatiotemporal_clusters[\"Spatiotemporal cluster size\"] = pd.to_numeric(\n",
    "            spatiotemporal_clusters[\"Spatiotemporal cluster size\"]\n",
    "        )\n",
    "\n",
    "        return spatiotemporal_clusters\n",
    "        \n",
    "    def calculate_amount_over_threshold_per_time_period(self, dataset, time_period):\n",
    "        \n",
    "        print('to-do')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
