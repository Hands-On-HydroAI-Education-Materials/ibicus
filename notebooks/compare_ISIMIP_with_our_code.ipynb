{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")  # path contains python_file.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import iris\n",
    "import numpy as np\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing data ISIMIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_and_preprocess_isimip_testing_data(variable, grid_point = [0,0]):\n",
    "    obs = np.array(iris.load_cube(\"testing_data/ISIMIP/\"+variable+\"_obs-hist_coarse_1979-2014.nc\").data)\n",
    "    cm_hist = np.array(iris.load_cube(\"testing_data/ISIMIP/\"+variable+\"_sim-hist_coarse_1979-2014.nc\").data)\n",
    "    cm_future = np.array(iris.load_cube(\"testing_data/ISIMIP/\"+variable+\"_sim-fut_coarse_2065-2100.nc\").data)\n",
    "    \n",
    "    obs = np.moveaxis(obs, -1, 0)\n",
    "    cm_hist = np.moveaxis(cm_hist, -1, 0)\n",
    "    cm_future = np.moveaxis(cm_future, -1, 0)\n",
    "\n",
    "    obs = obs[:,  grid_point[0], grid_point[1]]\n",
    "    cm_hist = cm_hist[:,  grid_point[0], grid_point[1]]\n",
    "    cm_future = cm_future[:,  grid_point[0], grid_point[1]]\n",
    "    \n",
    "    return obs, cm_hist, cm_future\n",
    "\n",
    "variables = ['hurs', 'pr', 'prsnratio', 'psl', 'rsds', 'sfcWind', 'tas', 'tasrange', 'tasskew']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison ISIMIP and PACKAGE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PACKAGE_NAME.debias import ISIMIP\n",
    "import PACKAGE_NAME.code_isimip.utility_functions as uf\n",
    "from PACKAGE_NAME.code_isimip.bias_adjustment import adjust_bias_one_month, map_quantiles_parametric_trend_preserving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: pseudo future observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ISIMIP(distribution=<scipy.stats._continuous_distns.norm_gen object at 0x7fdffb03fe80>, trend_preservation_method='additive', detrending=True, reasonable_physical_range=[0, 400], variable='tas', lower_bound=-inf, lower_threshold=-inf, upper_bound=inf, upper_threshold=inf, trend_removal_with_significance_test=True, trend_transfer_only_for_values_within_threshold=True, event_likelihood_adjustment=False, ecdf_method='linear_interpolation', iecdf_method='linear', running_window_mode=True, running_window_length=31, running_window_step_length=1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs, cm_hist, cm_future = read_in_and_preprocess_isimip_testing_data(\"tas\")\n",
    "\n",
    "debiaser = ISIMIP.from_variable(variable=\"tas\")\n",
    "debiaser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9793885001521144\n",
      "0.02037198862541345\n",
      "0.0005858738172709933\n"
     ]
    }
   ],
   "source": [
    "future_observations = debiaser.step5(obs, cm_hist, cm_future)\n",
    "future_observations_isimip = uf.map_quantiles_non_parametric_trend_preserving(\n",
    "    x_obs_hist = obs, x_sim_hist = cm_hist, x_sim_fut = cm_future, \n",
    "    trend_preservation = debiaser.trend_preservation_method, \n",
    "    n_quantiles = min(obs.size, cm_hist.size, cm_future.size)-1,\n",
    "    max_change_factor = 100., max_adjustment_factor = 9.,\n",
    "    adjust_obs = True, \n",
    "    lower_bound = None if np.isinf(debiaser.lower_bound) else debiaser.lower_bound,\n",
    "    upper_bound = None if np.isinf(debiaser.upper_bound) else debiaser.upper_bound\n",
    ")\n",
    "\n",
    "print(sum(np.isclose(future_observations, future_observations_isimip))/cm_future.size)\n",
    "print(np.max(np.abs(future_observations - future_observations_isimip)))\n",
    "print(np.mean(np.abs(future_observations - future_observations_isimip)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that ISIMIP and own implementation are in relative agreement regarding the generated pseudo-future observations. Small deviations exist which are probably due to the way ISIMIP computes the inverse cdf:\n",
    "\n",
    "```python\n",
    "from PACKAGE_NAME.code_isimip.utility_functions import percentile1d\n",
    "x_obs_hist = obs\n",
    "x_sim_hist = cm_hist\n",
    "x_sim_fut = cm_future\n",
    "\n",
    "n_quantiles = min(obs.size, cm_hist.size, cm_future.size)-1\n",
    "n = min([n_quantiles + 1, x_obs_hist.size, x_sim_hist.size, x_sim_fut.size])\n",
    "p_zeroone = np.linspace(0., 1., n)\n",
    "\n",
    "# compute quantiles of input data\n",
    "q_obs_hist = percentile1d(x_obs_hist, p_zeroone)\n",
    "q_sim_hist = percentile1d(x_sim_hist, p_zeroone)\n",
    "q_sim_fut = percentile1d(x_sim_fut, p_zeroone)\n",
    "\n",
    "# compute quantiles needed for quantile delta mapping\n",
    "p = np.interp(x_obs_hist, q_obs_hist, p_zeroone)\n",
    "F_sim_fut_inv  = np.interp(p, p_zeroone, q_sim_fut)\n",
    "F_sim_hist_inv = np.interp(p, p_zeroone, q_sim_hist)\n",
    "F_obs_hist_inv = np.interp(p, p_zeroone, q_obs_hist)\n",
    "y = F_obs_hist_inv + F_sim_fut_inv - F_sim_hist_inv\n",
    "\n",
    "```\n",
    "\n",
    "The double interpolation in `p = np.interp(obs, q_obs_hist, p_zeroone)` and `F_sim_fut_inv  = np.interp(p, p_zeroone, q_sim_fut)`sometimes introduces artifacts and leads to different results than the more straightforward: \n",
    "\n",
    "```python\n",
    "from PACKAGE_NAME.math_helpers import ecdf, iecdf\n",
    "\n",
    "obs_hist = obs\n",
    "\n",
    "# Compute p = F_obs_hist(x) with x in obs_hist\n",
    "p = ecdf(obs_hist, obs_hist, n = n)\n",
    "\n",
    "# Compute q-vals: q = IECDF(p)\n",
    "q_obs_hist = obs_hist  # TODO: = iecdf_obs_hist(p), appears in eq. 7\n",
    "q_cm_future = iecdf(cm_future, p, method=debiaser.iecdf_method)\n",
    "q_cm_hist = iecdf(cm_hist, p, method=debiaser.iecdf_method)\n",
    "```\n",
    "\n",
    "The values in our `p` and ISIMIP's ones agree and the inverses up to a small difference.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methodical comparison: bring to work later"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "max_deviation = np.zeros(len(variables))\n",
    "percent_agreement = np.zeros(len(variables))\n",
    "\n",
    "for i, variable in enumerate(variables):\n",
    "    obs, cm_hist, cm_future = read_in_and_preprocess_isimip_testing_data(variable)\n",
    "    debiaser = ISIMIP.from_variable(variable=variable)\n",
    "    \n",
    "    # Compute future observations\n",
    "    future_observations = debiaser.step5(obs, cm_hist, cm_future)\n",
    "    future_observations_isimip = uf.map_quantiles_non_parametric_trend_preserving(\n",
    "        x_obs_hist = obs, x_sim_hist = cm_hist, x_sim_fut = cm_future, \n",
    "        trend_preservation = debiaser.trend_preservation_method, \n",
    "        n_quantiles = min(obs.size, cm_hist.size, cm_future.size)-1,\n",
    "        max_change_factor = 100., max_adjustment_factor = 9.,\n",
    "        adjust_obs = True, \n",
    "        lower_bound = None if np.isinf(debiaser.lower_bound) else debiaser.lower_bound,\n",
    "        upper_bound = None if np.isinf(debiaser.upper_bound) else debiaser.upper_bound\n",
    "    )\n",
    "    \n",
    "    max_deviation[i] = np.max(np.abs(future_observations - future_observations_isimip))\n",
    "    percent_agreement[i] = np.sum(np.isclose(future_observations, future_observations_isimip))/future_observations.size\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Quantile transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First: work with future observations from ISIMIP in step5 and run them through step6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from PACKAGE_NAME.code_isimip.bias_adjustment import adjust_bias_one_month, map_quantiles_parametric_trend_preserving\n",
    "import PACKAGE_NAME.code_isimip.utility_functions as uf\n",
    "\n",
    "obs, cm_hist, cm_future = read_in_and_preprocess_isimip_testing_data(\"tas\")\n",
    "debiaser = ISIMIP.from_variable(variable=\"tas\")\n",
    "\n",
    "future_observations_isimip = uf.map_quantiles_non_parametric_trend_preserving(\n",
    "    x_obs_hist = obs, x_sim_hist = cm_hist, x_sim_fut = cm_future, \n",
    "    trend_preservation = debiaser.trend_preservation_method, \n",
    "    n_quantiles = min(obs.size, cm_hist.size, cm_future.size)-1,\n",
    "    max_change_factor = 100., max_adjustment_factor = 9.,\n",
    "    adjust_obs = True, \n",
    "    lower_bound = None if np.isinf(debiaser.lower_bound) else debiaser.lower_bound,\n",
    "    upper_bound = None if np.isinf(debiaser.upper_bound) else debiaser.upper_bound\n",
    ")\n",
    "\n",
    "step6_using_isimip_obs_future = debiaser.step6(obs, future_observations_isimip, cm_hist, cm_future)\n",
    "isimip_mapping = map_quantiles_parametric_trend_preserving(\n",
    "    x_obs_hist = obs, x_sim_hist = cm_hist, x_sim_fut = cm_future, \n",
    "    distribution = \"normal\", \n",
    "    trend_preservation = debiaser.trend_preservation_method, \n",
    "    adjust_p_values=debiaser.event_likelihood_adjustment,\n",
    "    lower_bound = None if np.isinf(debiaser.lower_bound) else debiaser.lower_bound,\n",
    "    lower_threshold = None if np.isinf(debiaser.lower_threshold) else debiaser.lower_threshold,\n",
    "    upper_bound = None if np.isinf(debiaser.upper_bound) else debiaser.upper_bound,\n",
    "    upper_threshold = None if np.isinf(debiaser.upper_threshold) else debiaser.upper_threshold,\n",
    "    unconditional_ccs_transfer = debiaser.trend_transfer_only_for_values_within_threshold,\n",
    "    trendless_bound_frequency = False, #???\n",
    "    n_quantiles = min(obs.size, cm_hist.size, cm_future.size)-1,\n",
    "    p_value_eps=1e-10,\n",
    "    max_change_factor=100.0,\n",
    "    max_adjustment_factor=9.0\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(np.max(np.abs(step6_using_isimip_obs_future-isimip_mapping)))\n",
    "print(np.sum(np.isclose(step6_using_isimip_obs_future, isimip_mapping))/isimip_mapping.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At least for tas ISIMIP and mine results are in agreement. TODO: check other options. Only thing that influences the results is n_quantiles determining the size of the ISIMIP-grid for computing quantiles. If it is smaller then deviations get larger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PACKAGE_NAME.code_isimip.bias_adjustment import adjust_bias_one_month\n",
    "\n",
    "obs, cm_hist, cm_future = read_in_and_preprocess_isimip_testing_data(\"tas\")\n",
    "debiaser = ISIMIP.from_variable(variable=\"tas\")\n",
    "\n",
    "isimip_adjustment = adjust_bias_one_month(\n",
    "    data = {'obs_hist': [obs], 'sim_hist': [cm_hist], 'sim_fut': [cm_future]},\n",
    "    years = {'obs_hist': np.repeat(np.arange(1979, 2015), 366)[:obs.size], 'sim_hist': np.repeat(np.arange(1979, 2015), 366)[:cm_hist.size], 'sim_fut': np.repeat(np.arange(2065, 2101), 366)[:cm_future.size]},\n",
    "    long_term_mean = {'obs_hist' : [obs.mean()], 'sim_hist' : [cm_hist.mean()], 'sim_fut' : [cm_future.mean()]},\n",
    "    lower_bound = [None if np.isinf(debiaser.lower_bound) else debiaser.lower_bound],\n",
    "    lower_threshold = [None if np.isinf(debiaser.lower_threshold) else debiaser.lower_threshold],\n",
    "    upper_bound = [None if np.isinf(debiaser.upper_bound) else debiaser.upper_bound],\n",
    "    upper_threshold = [None if np.isinf(debiaser.upper_threshold) else debiaser.upper_threshold],\n",
    "    unconditional_ccs_transfer=[debiaser.trend_transfer_only_for_values_within_threshold],\n",
    "    trendless_bound_frequency=[False],\n",
    "    randomization_seed=None,\n",
    "    detrend=[False],#debiaser.detrending],\n",
    "    rotation_matrices=[],\n",
    "    n_quantiles=min(obs.size, cm_hist.size, cm_future.size)-1,\n",
    "    distribution=[\"normal\"],\n",
    "    trend_preservation=[debiaser.trend_preservation_method],\n",
    "    adjust_p_values=[debiaser.event_likelihood_adjustment],\n",
    "    invalid_value_warnings=True\n",
    ")[0]\n",
    "\n",
    "my_adjustment = debiaser._apply_on_window(obs, cm_hist, cm_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.isclose(isimip_adjustment, my_adjustment))/my_adjustment.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without detrending my results are exactly the same as isimips. Look at it on a monthly basis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cf_units import num2date\n",
    "\n",
    "def get_dates(x):\n",
    "    time_dimension = x.coords()[2]\n",
    "    dates = time_dimension.units.num2date(time_dimension.points)\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_and_preprocess_isimip_testing_data_with_dates(variable, grid_point = [0,0]):\n",
    "    \n",
    "    obs = iris.load_cube(\"testing_data/ISIMIP/\"+variable+\"_obs-hist_coarse_1979-2014.nc\")\n",
    "    cm_hist = iris.load_cube(\"testing_data/ISIMIP/\"+variable+\"_sim-hist_coarse_1979-2014.nc\")\n",
    "    cm_future = iris.load_cube(\"testing_data/ISIMIP/\"+variable+\"_sim-fut_coarse_2065-2100.nc\")\n",
    "\n",
    "    dates = {\n",
    "        \"obs\": get_dates(obs),\n",
    "        \"cm_hist\": get_dates(cm_hist),\n",
    "        \"cm_future\": get_dates(cm_future)\n",
    "    }\n",
    "    \n",
    "    obs = np.array(obs.data)\n",
    "    cm_hist = np.array(cm_hist.data)\n",
    "    cm_future = np.array(cm_future.data)\n",
    "\n",
    "    \n",
    "    obs = np.moveaxis(obs, -1, 0)\n",
    "    cm_hist = np.moveaxis(cm_hist, -1, 0)\n",
    "    cm_future = np.moveaxis(cm_future, -1, 0)\n",
    "\n",
    "    obs = obs[:,  grid_point[0], grid_point[1]]\n",
    "    cm_hist = cm_hist[:,  grid_point[0], grid_point[1]]\n",
    "    cm_future = cm_future[:,  grid_point[0], grid_point[1]]\n",
    "    \n",
    "    return obs, cm_hist, cm_future, dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day(x):\n",
    "    return x.day\n",
    "\n",
    "def month(x):\n",
    "    return x.month\n",
    "\n",
    "def year(x):\n",
    "    return x.year\n",
    "\n",
    "day = np.vectorize(day)\n",
    "month = np.vectorize(month)\n",
    "year = np.vectorize(year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9973118279569892"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PACKAGE_NAME.code_isimip.bias_adjustment import adjust_bias_one_month\n",
    "\n",
    "obs, cm_hist, cm_future, dates = read_in_and_preprocess_isimip_testing_data_with_dates(\"tas\")\n",
    "debiaser = ISIMIP.from_variable(variable=\"tas\")\n",
    "\n",
    "obs_jan = obs[month(dates[\"obs\"]) == 1]\n",
    "cm_hist_jan = cm_hist[month(dates[\"cm_hist\"]) == 1]\n",
    "cm_future_jan = cm_future[month(dates[\"cm_future\"]) == 1]\n",
    "isimip_adjustment = adjust_bias_one_month(\n",
    "    data = {'obs_hist': [obs_jan], 'sim_hist': [cm_hist_jan], 'sim_fut': [cm_future_jan]},\n",
    "    years = {'obs_hist': np.repeat(np.arange(1979, 2015), 31)[:obs_jan.size], 'sim_hist': np.repeat(np.arange(1979, 2015), 31)[:cm_hist_jan.size], 'sim_fut': np.repeat(np.arange(2065, 2101), 31)[:cm_future_jan.size]},\n",
    "    long_term_mean = {'obs_hist' : [obs.mean()], 'sim_hist' : [cm_hist.mean()], 'sim_fut' : [cm_future.mean()]},\n",
    "    lower_bound = [None if np.isinf(debiaser.lower_bound) else debiaser.lower_bound],\n",
    "    lower_threshold = [None if np.isinf(debiaser.lower_threshold) else debiaser.lower_threshold],\n",
    "    upper_bound = [None if np.isinf(debiaser.upper_bound) else debiaser.upper_bound],\n",
    "    upper_threshold = [None if np.isinf(debiaser.upper_threshold) else debiaser.upper_threshold],\n",
    "    unconditional_ccs_transfer=[debiaser.trend_transfer_only_for_values_within_threshold],\n",
    "    trendless_bound_frequency=[False],\n",
    "    randomization_seed=None,\n",
    "    detrend=[debiaser.detrending],\n",
    "    rotation_matrices=[],\n",
    "    n_quantiles=min(obs_jan.size, cm_hist_jan.size, cm_future_jan.size)-1,\n",
    "    distribution=[\"normal\"],\n",
    "    trend_preservation=[debiaser.trend_preservation_method],\n",
    "    adjust_p_values=[debiaser.event_likelihood_adjustment],\n",
    "    invalid_value_warnings=True\n",
    ")[0]\n",
    "#debiaser.detrending = False\n",
    "my_adjustment = debiaser._apply_on_window(obs_jan, cm_hist_jan, cm_future_jan)\n",
    "\n",
    "np.sum(np.isclose(isimip_adjustment, my_adjustment))/my_adjustment.size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I run it only on january the results are equal also with detrending. \n",
    "\n",
    "Open issues:\n",
    "- Iteration over month and how do we pass time to ISIMIP-apply function (used for month-iteration and detrending to group together years) + how to implement the running window mode if no time was passed to the apply-function, but also if it is passed (then we can still group together years for both window and detrending if passed):\n",
    "    - Can add different optional arguments like months = {\"obs\": [], \"cm_hist\": []}, or bigger months_obs, months_cm_hist, etc. time_obs, time_cm_hist (then what time-format?), year_obs, year_cm_hist --> form as much time-information as we can get out of that. What is most useful and comfortable for user.\n",
    "    - Show equivalence with ISIMIP-implementation.\n",
    "    - Is time used somewhere else other than to define iteration-periods and detrending? I don't think so, but check!\n",
    "- Lot's of ISIMIP options and versions. What do we take as parameter and how do we structure initalisation?\n",
    "    - Do we want to offer version-selection or just implement v2.5? If we want to offer that: what do we need to add as parameters\n",
    "    - Code-proposal: dataclass and fromn_variable option for each debiaser. Is that useful? How do we construct a debiaser?\n",
    "    - Concrete questions/isimip-options: \n",
    "        - One still unclear ISIMIP-option\n",
    "        - p-value thresholding as option? Or implemented fixed\n",
    "        - add option to pass year or date generally?\n",
    "- Do we want each debiaser as dataclass with a normal init-method and one from_variable one or is init alright. Could for example change linear scaling to a dataclass that can be initialised with scaling-method and from_variable one.\n",
    "- Is dataclass the correct type because it is not about arbitrary data but about complicated configs.\n",
    " \n",
    "TODO:\n",
    "- Do we want to have ISIMIP-modes?\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things that are different in different ISIMIP-versions: \n",
    "- \"trend_removal_with_significance_test\": True,  # >= v2.1, step 3\n",
    "- \"powerlaw_exponent_step4\": 1,  # >= v2.2: uniform distribution, step 4\n",
    "- \"pseudo_future_observations_bounded_variables\": \"v2.3\",  # >= v2.3: new equation, step 5\n",
    "- \"trend_transfer_only_for_values_within_threshold\": True,  # >= v2.4,  step 5\n",
    "- which equation is used for getting the bounds in step6\n",
    "- which variables are affected by detrending\n",
    "- for which variables the event likelihood is adjusted\n",
    "- running window mode with params (v2.5)\n",
    "- lots of chaos happening with hurs (not entirely sure what is going on there?)\n",
    "- stuff I missed\n",
    "\n",
    "\n",
    "what do we need options for?\n",
    "\n",
    "- trend_removal_with_significance_test\n",
    "- trend_transfer_only_for_values_within_threshold\n",
    "- running window mode\n",
    "- variable options:\n",
    "    -   \"lower_bound\": 0,\n",
    "        \"lower_threshold\": 0.01,\n",
    "        \"upper_bound\": 100,\n",
    "        \"upper_threshold\": 99.99,\n",
    "        \"distribution\": scipy.stats.beta,\n",
    "        \"trend_preservation_method\": \"bounded\",\n",
    "        \"detrending\": False,\n",
    "        \"event_likelihood_adjustment\": False,  # >= v2.5 step 6\n",
    "\n",
    "I would argue we can kick out:\n",
    "    - powerlaw exponent\n",
    "    - equation used for getting hte bounds in step6\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datetime passing\n",
    "\n",
    "We need datetimes in python datetime format (or any other format having .month, .day and .year attributes). A numpy datetime64 can be easily converted using:\n",
    "\n",
    "```python\n",
    "datetime64Obj = np.datetime64('2002-07-04T02:55:41-0700')\n",
    "print datetime64Obj.astype(object).year\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([265.71384, 265.7729 , 266.5618 , ..., 281.1639 , 278.05957,\n",
       "       277.32367], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs, cm_hist, cm_future, dates = read_in_and_preprocess_isimip_testing_data_with_dates(\"tas\")\n",
    "debiaser = ISIMIP.from_variable(variable=\"tas\")\n",
    "debiaser.running_window_mode = False\n",
    "\n",
    "my_adjustment = debiaser.apply_location(obs, cm_hist, cm_future, *dates.values())\n",
    "my_adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'obs': array([cftime.DatetimeProlepticGregorian(1979, 1, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "        cftime.DatetimeProlepticGregorian(1979, 1, 2, 0, 0, 0, 0, has_year_zero=True),\n",
       "        cftime.DatetimeProlepticGregorian(1979, 1, 3, 0, 0, 0, 0, has_year_zero=True),\n",
       "        ...,\n",
       "        cftime.DatetimeProlepticGregorian(2014, 12, 29, 0, 0, 0, 0, has_year_zero=True),\n",
       "        cftime.DatetimeProlepticGregorian(2014, 12, 30, 0, 0, 0, 0, has_year_zero=True),\n",
       "        cftime.DatetimeProlepticGregorian(2014, 12, 31, 0, 0, 0, 0, has_year_zero=True)],\n",
       "       dtype=object),\n",
       " 'cm_hist': array([cftime.DatetimeProlepticGregorian(1979, 1, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "        cftime.DatetimeProlepticGregorian(1979, 1, 2, 0, 0, 0, 0, has_year_zero=True),\n",
       "        cftime.DatetimeProlepticGregorian(1979, 1, 3, 0, 0, 0, 0, has_year_zero=True),\n",
       "        ...,\n",
       "        cftime.DatetimeProlepticGregorian(2014, 12, 29, 0, 0, 0, 0, has_year_zero=True),\n",
       "        cftime.DatetimeProlepticGregorian(2014, 12, 30, 0, 0, 0, 0, has_year_zero=True),\n",
       "        cftime.DatetimeProlepticGregorian(2014, 12, 31, 0, 0, 0, 0, has_year_zero=True)],\n",
       "       dtype=object),\n",
       " 'cm_future': array([cftime.DatetimeProlepticGregorian(2065, 1, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "        cftime.DatetimeProlepticGregorian(2065, 1, 2, 0, 0, 0, 0, has_year_zero=True),\n",
       "        cftime.DatetimeProlepticGregorian(2065, 1, 3, 0, 0, 0, 0, has_year_zero=True),\n",
       "        ...,\n",
       "        cftime.DatetimeProlepticGregorian(2100, 12, 29, 0, 0, 0, 0, has_year_zero=True),\n",
       "        cftime.DatetimeProlepticGregorian(2100, 12, 30, 0, 0, 0, 0, has_year_zero=True),\n",
       "        cftime.DatetimeProlepticGregorian(2100, 12, 31, 0, 0, 0, 0, has_year_zero=True)],\n",
       "       dtype=object)}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
